#!/usr/bin/env bash
#shellcheck disable=SC1091
# checkpoint - Create and restore timestamped directory snapshots
#
# Features: atomic backups, concurrency protection, remote SSH operations,
#           metadata tagging, selective restore, checkpoint comparison
#
# Usage: checkpoint [OPTIONS] [directory]
#        checkpoint --list [-d DIR]
#        checkpoint --restore [--from ID] [--to DIR]
#        checkpoint --remote user@host:/path [OPTIONS]
#
# Version: 1.6.1
# License: GPL-3.0
set -euo pipefail

# Ensure consistent environment
export PATH="/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:$PATH"
export LC_ALL=C

# Core configuration
readonly -- VERSION='1.6.1'
readonly -- TIMESTAMP_PATTERN='20[0-9][0-9][0-1][0-9][0-3][0-9]_[0-2][0-9][0-5][0-9][0-5][0-9]*'
declare -- HARDLINK
HARDLINK=$(command -v hardlink || echo '')

# Script identification using standard pattern
#shellcheck disable=SC2155
declare -r SCRIPT_PATH=$(realpath -e "$0" 2>/dev/null || echo "$0")
declare -r SCRIPT_NAME=${SCRIPT_PATH##*/} #SCRIPT_DIR=${SCRIPT_PATH%/*}

# =============================================================================
# ENVIRONMENT AND MESSAGING
# =============================================================================

# Terminal colors (disabled if not a TTY)
#shellcheck disable=SC2015
[[ -t 2 ]] && declare -- RED=$'\033[0;31m' GREEN=$'\033[0;32m' YELLOW=$'\033[0;33m' CYAN=$'\033[0;36m' NC=$'\033[0m' || declare -- RED='' GREEN='' YELLOW='' CYAN='' NC=''
readonly -- RED GREEN YELLOW CYAN NC
# For backward compatibility
declare -- BOLD NOCOLOR
[[ -t 1 ]] && BOLD=$'\033[1m' || BOLD=''
[[ -t 1 ]] && NOCOLOR=$'\033[0m' || NOCOLOR=''
readonly -- BOLD NOCOLOR

# Global verbosity setting
declare -i verbose=1

# Messaging functions: _msg (core), info, warn, error, die, vecho, success
_msg() {
  local -- status="${FUNCNAME[1]}" prefix="$SCRIPT_NAME:" msg
  case "$status" in
    success) prefix+=" ${GREEN}✓${NC}" ;;
    warn)    prefix+=" ${YELLOW}▲${NC}" ;;
    info)    prefix+=" ${CYAN}◉${NC}" ;;
    error)   prefix+=" ${RED}✗${NC}" ;;
    *)       ;;
  esac
  for msg in "$@"; do printf '%s %s\n' "$prefix" "$msg"; done
}
# Conditional output based on verbosity
vecho() { ((verbose)) || return 0; _msg "$@"; }
success() { ((verbose)) || return 0; >&2 _msg "$@"; }
warn() { ((verbose)) || return 0; >&2 _msg "$@"; }
info() { ((verbose)) || return 0; >&2 _msg "$@"; }
# Unconditional output
error() { >&2 _msg "$@"; }
die() { (($# > 1)) && error "${@:2}"; exit "${1:-0}"; }

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

# decp: Debug helper - display variable declarations
decp() { declare -p "$@" | sed 's/^declare -[a-zA-Z-]* //'; }

# Trim whitespace
trim() {
  local v="$*"
  v="${v#"${v%%[![:blank:]]*}"}"
  echo -n "${v%"${v##*[![:blank:]]}"}"
}

# Pluralization helper
s() { (( ${1:-1} == 1 )) || echo -n 's'; }

# yes/no prompt
yn() {
  ((verbose)) || return 0
  local -- reply
  read -r -n1 -p "$SCRIPT_NAME: ${YELLOW}$1${NC} y/n " reply
  echo
  [[ ${reply,,} == y ]]
}

# Verify required dependencies
for cmd in rsync find stat; do
  command -v "$cmd" >/dev/null 2>&1 || die 1 "Required command '$cmd' not found."
done

# check_dir_access: Test if current user can write to a directory
# Determines whether the current user has write permissions for backup operations
# without requiring privilege escalation
# Args: $1 - directory path to test
# Returns: 0 if writable, 1 if not writable or doesn't exist
# Example: check_dir_access "/var/backups"
check_dir_access() {
  local -- test_dir="$1"

  # If directory doesn't exist, check if we can create it
  if [[ ! -d "$test_dir" ]]; then
    # Check parent directory for write access
    local -- parent_dir
    parent_dir=$(dirname "$test_dir")

    # Keep going up until we find an existing directory
    while [[ ! -d "$parent_dir" ]] && [[ "$parent_dir" != "/" ]]; do
      parent_dir=$(dirname "$parent_dir")
    done

    # Test if we can write to the parent
    [[ -w "$parent_dir" ]]
    return $?
  fi

  # Directory exists, test if we can write to it
  [[ -w "$test_dir" ]]
  return $?
}

# is_root_or_sudo: Check if script is running with root privileges
# Determines whether the current process has root privileges either
# directly (EUID=0) or through sudo
# Returns: 0 if running as root, 1 otherwise
# Globals: EUID
is_root_or_sudo() {
  ((EUID == 0))
}

# get_default_backup_dir: Determine appropriate default backup directory
# Selects the default backup directory based on user privileges and
# environment settings. Prefers user-accessible locations for non-root users.
# Args: $1 - source directory name
# Returns: Prints the default backup directory path
# Globals: EUID, HOME, CHECKPOINT_BACKUP_DIR
get_default_backup_dir() {
  local -- dir_name="$1"

  # Check if user specified a default via environment variable
  if [[ -n "${CHECKPOINT_BACKUP_DIR:-}" ]]; then
    echo "${CHECKPOINT_BACKUP_DIR}/${dir_name}"
    return 0
  fi

  # If running as root or with sudo, use system location
  if is_root_or_sudo; then
    echo "/var/backups/${dir_name}"
    return 0
  fi

  # For non-root users, prefer home directory
  # Use .checkpoint for better organization and visibility
  echo "${HOME}/.checkpoint/${dir_name}"
  return 0
}

# Smart privilege escalation - only escalate if backup directory requires it
# Parse arguments to determine if privilege escalation is needed
declare -- parsed_backup_dir=""
declare -i no_sudo_flag=0
declare -i need_escalation=0

# Quick parse to find backup directory and no-sudo flag
for ((i=1; i<=$#; i++)); do
  arg="${!i}"
  case "$arg" in
    -d|--backup-dir)
      ((i++))
      if ((i <= $#)); then
        parsed_backup_dir="${!i}"
      fi
      ;;
    --no-sudo)
      no_sudo_flag=1
      ;;
  esac
done

# Determine if we need privilege escalation
if ((EUID != 0)) && ((no_sudo_flag == 0)); then
  # We're not root and sudo is allowed

  # If backup dir is specified, check if it needs privileges
  if [[ -n "$parsed_backup_dir" ]]; then
    if ! check_dir_access "$parsed_backup_dir"; then
      # Directory is not accessible, need privileges
      need_escalation=1
    fi
  else
    # No backup dir specified - check the default
    # Note: We can't determine the source dir name here without more parsing
    # So we check if /var/backups would be accessible (the traditional default)
    if ! check_dir_access "/var/backups"; then
      # Traditional location not accessible
      # But we might use a user directory instead, so don't escalate yet
      need_escalation=0
    fi
  fi

  # If we determined we need escalation, try to escalate
  if ((need_escalation)); then
    if sudo -ln &>/dev/null; then
      # Sudo is available, re-run with elevated privileges
      info "Elevating privileges for backup directory access"
      sudo -n "$0" "$@"
      exit $?
    else
      # Sudo not available but directory requires it
      # Let the script continue and fail with a proper error message later
      :
    fi
  fi
fi

# noarg: Verify command option has required argument
# Validates that command-line options have proper arguments and prevents
# options from being treated as arguments to other options
# Args: $1 - option name, $2+ - remaining args
# Returns: 0 if valid, dies with error if missing argument
# Example: noarg "--backup-dir" "$@"
noarg() {
  if (($# < 2)) || [[ ${2:0:1} == '-' ]]; then
    die 2 "Missing argument for option '$1'"
  fi
  return 0
}

# isodate: Generate timestamp in YYYYMMDD_HHMMSS format for checkpoint names
# Creates consistent timestamp format used throughout the application for
# checkpoint directory naming and ensuring sortable backup ordering
# Returns: Current time in YYYYMMDD_HHMMSS format (e.g., "20250430_143052")
isodate() { date +'%Y%m%d_%H%M%S'; }

# xcleanup: Clean up on script exit
# Exit handler function registered with trap to ensure clean script termination
# Also releases any locks that may be held and removes temporary directories
# Args: $1 - exit code to use (default: 0)
# Returns: Never returns (exits with specified code)
# Globals: lock_dir, use_locking, temp_backup_dir
xcleanup() { 
  local -i exitcode=${1:-0}
  
  # Release lock if we're holding one
  if ((use_locking)) && [[ -n "$lock_dir" ]]; then
    release_lock >/dev/null 2>&1 || true
  fi
  
  # Clean up temporary backup directory if it exists
  if [[ -n "$temp_backup_dir" ]] && [[ -d "$temp_backup_dir" ]]; then
    rm -rf "$temp_backup_dir" 2>/dev/null || true
  fi
  
  exit "$exitcode"
}
trap 'xcleanup $?' SIGINT SIGTERM EXIT

# =============================================================================
# GLOBAL CONFIGURATION
# =============================================================================
# All state variables, set via command-line parsing or environment detection

# Core settings
declare -- source_dir=''    # Directory to back up (defaults to PWD)
declare -- backup_dir=''    # Where checkpoints are stored (defaults to /var/backups/DIR_NAME)
declare -- suffix=''        # Optional suffix for checkpoint names (sanitized alphanumeric)
# verbose already declared globally above
declare -i debug=0          # Enable debug information output
declare -i list_mode=0      # List checkpoints instead of creating new ones
declare -i hardlink
hardlink=$( [[ -n "$HARDLINK" ]] && echo 1 || echo 0 ) # Use hardlinking when available for space efficiency
declare -a exclude_patterns=() # User-defined exclusion patterns beyond defaults

# Remote operation settings
declare -i remote_mode=0    # Enable remote operations via SSH
declare -- remote_spec=''   # Full remote specification (user@host:/path format)
declare -- remote_user=''   # Parsed remote username from remote_spec
declare -- remote_host=''   # Parsed remote hostname from remote_spec
declare -- remote_path=''   # Parsed remote path from remote_spec
declare -i remote_timeout=30 # SSH connection timeout in seconds

# Backup rotation settings
declare -i keep_count=0     # Number of recent backups to keep (0 = keep all)
declare -i age_days=0       # Maximum age in days for backups (0 = keep all)
declare -i prune_only=0     # Only prune old backups without creating new backup

# Restore operation settings
declare -i restore_mode=0   # Enable restore mode instead of backup creation
declare -- restore_source='' # Source checkpoint ID to restore from (timestamp or partial match)
declare -- restore_target='' # Target directory to restore to (defaults to original location)
declare -i dry_run=0        # Preview restoration changes without making them
declare -i diff_mode=0      # Show differences between current files and checkpoint
declare -a restore_files=() # File patterns for selective restoration

# Comparison operation settings
declare -i compare_mode=0   # Enable checkpoint-to-checkpoint comparison mode
declare -- compare_source='' # Second checkpoint ID to compare with first
declare -i compare_detailed=0 # Show detailed file content differences in comparison

# Additional operational settings
declare -i verify_mode=0    # Verify backup integrity after creation using checksums
declare -i no_sudo=0        # Never attempt sudo privilege escalation

# Metadata management settings
declare -i metadata_mode=0  # Enable metadata operations (show, update, find)
declare -- metadata_action='' # Metadata action type: show, update, or find
declare -- metadata_checkpoint='' # Checkpoint ID for metadata operation
declare -- description=''   # Human-readable checkpoint description text
declare -- system_name=''   # Source system identifier for checkpoint metadata
declare -a tags=()          # Array of key-value metadata tags (KEY=VALUE format)

# Lock management settings
declare -i use_locking=1    # Enable lockfile mechanism for concurrency protection (default: enabled)
declare -i lock_timeout=300 # Timeout in seconds for acquiring lock (default: 5 minutes)
declare -i force_unlock=0   # Force removal of stale locks
declare -- lock_dir=''      # Path to current lock directory (set by acquire_lock)

# Atomic operation settings
declare -- temp_backup_dir='' # Temporary directory for atomic backup operations

# Display help and usage information
usage() {
  cat <<EOT
$SCRIPT_NAME $VERSION - create and restore checkpoint backups

Creates timestamped backup snapshots of a directory.

Default backup locations:
 - Root/sudo users: /var/backups/DIR_NAME/TIMESTAMP[_SUFFIX]
 - Non-root users:  ~/.checkpoint/DIR_NAME/TIMESTAMP[_SUFFIX]
 - Custom location: Set CHECKPOINT_BACKUP_DIR environment variable

Automatic exclusions:
 - Directories: backup_dir, .gudang/, temp/, .temp/, tmp/
 - Files: *~ ~*

Privilege handling:
 - Automatically detects if sudo is needed for backup directory
 - Use --no-sudo to prevent privilege escalation
 - Non-root users can backup to user-writable directories

To enable hardlinking (for space efficiency), install hardlink:
    apt install hardlink

Usage:
  $SCRIPT_NAME [OPTIONS] [directory]                   # Create checkpoint
  $SCRIPT_NAME --list [OPTIONS] [directory]            # List checkpoints
  $SCRIPT_NAME --restore [RESTORE_OPTIONS] [directory] # Restore from checkpoint

Options:
  -d, --backup-dir DIR  Backup directory for checkpoints
                        (default: context-dependent, see above)
  -s, --suffix SUF      Optional suffix to add to checkpoint name
                        (alphanumeric, dots, underscores and hyphens only)
  -n, --no-hardlink     Do not hardlink to previous backup
      --hardlink        Hardlink to previous backup (default if available)
  -q, --quiet           Quiet mode, minimal output
  -v, --verbose         Verbose output (default)
  -l, --list            List existing checkpoints instead of creating new one
  -x, --exclude PATTERN Exclude files/directories matching pattern (can be used multiple times)
      --no-sudo         Do not attempt to use sudo for privilege escalation
      --debug           Show debug information during operation
      --verify          Verify backup integrity after creation
      --metadata        Perform metadata operations
      --show ID         Show metadata for checkpoint ID
      --update ID       Update metadata for checkpoint ID
      --find PATTERN    Find checkpoints matching metadata pattern
      --desc TEXT       Set checkpoint description
      --system NAME     Set source system name
      --tag KEY=VALUE   Add tag to checkpoint metadata (can be used multiple times)
      --set KEY=VALUE   Set/update metadata key-value pair
      --remote SPEC     Remote destination in format user@host:/path
      --timeout SECONDS SSH connection timeout (default: 30 seconds)
      --keep NUM        Keep only specified number of most recent backups
      --age DAYS        Keep only backups newer than specified days
  -p, --prune-only      Only prune backups without creating a new one
      --no-lock         Disable lockfile mechanism (allows concurrent operations - DANGEROUS)
      --lock-timeout SECONDS  Timeout for acquiring lock (default: 300 seconds / 5 minutes)
      --force-unlock    Force removal of stale locks before proceeding
  -V, --version         Print version and exit ($VERSION)
  -h, --help            Display this help

Restore Options:
  -r, --restore         Restore from checkpoint backup
  -f, --from ID         Source checkpoint to restore from (timestamp or name)
                        If not specified, uses the most recent checkpoint
  -t, --to DIR          Target directory to restore to
                        If not specified, uses the original directory
      --dry-run         Show what would be restored without making changes
      --diff            Show differences between current files and checkpoint
                        Shows what would change during restoration without making changes
      --compare-with ID Compare two checkpoints with each other
                        The first checkpoint is the one specified with --from or the latest
                        The second checkpoint is the one specified with --compare-with
      --detailed        Show detailed output for checkpoint comparison
                        (includes specific differences for each file)
      --files PATTERN   Specific files or patterns to restore or compare (can be used multiple times)

Examples:
  # Create checkpoint of current directory (uses smart defaults)
  $SCRIPT_NAME

  # Non-root user: backup to home directory
  $SCRIPT_NAME ~/myproject  # Backs up to ~/.checkpoint/myproject/

  # Specify custom backup directory
  $SCRIPT_NAME -d ~/backups/myproject ~/myscript

  # Use environment variable for default location
  export CHECKPOINT_BACKUP_DIR=~/my-backups
  $SCRIPT_NAME ~/myproject  # Backs up to ~/my-backups/myproject/

  # Create checkpoint with descriptive suffix
  $SCRIPT_NAME -s "before-api-refactor"

  # Prevent sudo escalation for system directories
  $SCRIPT_NAME --no-sudo ~/myproject
  
  # List existing checkpoints
  $SCRIPT_NAME --list

  # Restore the latest checkpoint
  $SCRIPT_NAME --restore

  # Restore a specific checkpoint (by timestamp/ID)
  $SCRIPT_NAME --restore --from 20250430_091429

  # Restore to a different directory
  $SCRIPT_NAME --restore --from 20250430_091429 --to ~/restored-project

  # Preview restoration (dry run)
  $SCRIPT_NAME --restore --dry-run

  # Restore only specific files
  $SCRIPT_NAME --restore --files "*.js" --files "docs/*.md"

  # Compare current files with checkpoint before restoration
  $SCRIPT_NAME --restore --diff

  # Compare specific files between current directory and checkpoint
  $SCRIPT_NAME --restore --diff --files "*.js"

  # Compare two checkpoints with each other
  $SCRIPT_NAME --from 20250430_091429 --compare-with 20250430_101530

  # Compare two checkpoints with detailed differences
  $SCRIPT_NAME --from 20250430_091429 --compare-with 20250430_101530 --detailed

  # Compare specific files between two checkpoints
  $SCRIPT_NAME --from 20250430_091429 --compare-with 20250430_101530 --files "*.js" --files "*.html"

  # Create checkpoint and keep only the 5 most recent backups
  $SCRIPT_NAME --keep 5

  # Create checkpoint and remove backups older than 30 days
  $SCRIPT_NAME --age 30

  # Prune backups without creating a new one
  $SCRIPT_NAME --prune-only --keep 3

Environment Variables:
  CHECKPOINT_BACKUP_DIR   Default backup directory for all operations
                          Overrides the built-in directory selection logic
                          Example: export CHECKPOINT_BACKUP_DIR=~/backups

  CHECKPOINT_AUTO_CONFIRM Automatically confirm directory creation prompts
                          Set to any value to skip interactive prompts
                          Example: export CHECKPOINT_AUTO_CONFIRM=1

Notes:
  - Non-root users can backup to any writable directory
  - The script automatically detects when sudo is needed
  - Use --no-sudo to ensure no privilege escalation occurs
  - Backups preserve file permissions and timestamps
  - Hardlinking saves space by linking unchanged files
EOT
  exit "${1:-0}"
}

# get_owner_info: Get owner and group of a file/directory in a cross-platform way
# Args: $1 - Path to file/directory
# Returns: Space-separated owner and group names (e.g. "user group")
get_owner_info() {
  local -- path="$1"
  local -- owner group
  
  if stat --version 2>/dev/null | grep -q GNU; then
    # GNU stat (Linux)
    owner=$(stat -c "%U" "$path")
    group=$(stat -c "%G" "$path")
  else
    # BSD stat (macOS)
    owner=$(stat -f "%Su" "$path")
    group=$(stat -f "%Sg" "$path")
  fi
  
  echo "$owner $group"
}

# get_canonical_path: Convert path to absolute/canonical form
# Args: $1 - Path to convert
# Returns: Absolute path with symlinks resolved when possible
get_canonical_path() {
  local -- path="$1"

  # First, check if the path exists
  if [[ -e "$path" ]]; then
    # Path exists, resolve it fully
    if command -v readlink >/dev/null 2>&1 && readlink -f -- "$path" >/dev/null 2>&1; then
      # Linux with GNU readlink
      readlink -f -- "$path"
    elif command -v realpath >/dev/null 2>&1; then
      # Systems with realpath
      realpath -- "$path" 2>/dev/null
    else
      # Simple fallback
      if [[ $path != /* ]]; then
        echo "$PWD/$path"
      else
        echo "$path"
      fi
    fi
  else
    # Path doesn't exist, just make it absolute without resolution
    if [[ $path != /* ]]; then
      # Relative path - make it absolute
      echo "$PWD/$path"
    else
      # Already absolute
      echo "$path"
    fi
  fi
}

# get_relative_path: Calculate relative path between two directories
# Args: $1 - Source directory, $2 - Target directory
# Returns: Relative path from source to target, or target path if calculation fails
get_relative_path() {
  local -- from="$1"
  local -- to="$2"
  
  if command -v realpath >/dev/null 2>&1; then
    # Use realpath if available
    realpath --relative-to="$from" "$to" 2>/dev/null || echo "$to"
  elif command -v python3 >/dev/null 2>&1; then
    # Fall back to python3 if available
    python3 -c "import os.path; print(os.path.relpath('$to', '$from'))" 2>/dev/null || echo "$to"
  else
    # Last resort: just return target path
    echo "$to"
  fi
}

# =============================================================================
# LOCK MANAGEMENT
# =============================================================================
# Directory-based locking to prevent concurrent operations on same backup dir

# acquire_lock: Create and acquire a lockfile for the given backup directory
# Prevents concurrent operations on the same backup directory
# Args: $1 - Backup directory path
# Returns: 0 on success, 1 on failure
# Globals: lock_dir, lock_timeout, force_unlock, verbose, debug
acquire_lock() {
  local -- backup_dir="$1"
  local -i lock_acquired=0
  local -i start_time
  start_time=$(date +%s)
  local -i current_time
  local elapsed_time
  local lock_pid
  local lock_timestamp
  
  # Set lock directory path
  lock_dir="$backup_dir/.checkpoint.lock"
  
  ((debug)) && echo "DEBUG: Attempting to acquire lock at $lock_dir"
  
  while ((lock_acquired == 0)); do
    # Try to create lock directory atomically
    if mkdir "$lock_dir" 2>/dev/null; then
      # Lock acquired, write our PID and timestamp
      echo "$$" > "$lock_dir/pid"
      date -u +%s > "$lock_dir/timestamp"
      hostname > "$lock_dir/hostname" 2>/dev/null || true
      lock_acquired=1
      ((verbose)) && echo "Lock acquired for backup directory: $backup_dir"
      ((debug)) && echo "DEBUG: Lock details - PID: $$, Dir: $lock_dir"
      return 0
    else
      # Lock exists, check if it's stale
      if [[ -f "$lock_dir/pid" ]]; then
        lock_pid=$(cat "$lock_dir/pid" 2>/dev/null || echo "0")
        lock_timestamp=$(cat "$lock_dir/timestamp" 2>/dev/null || echo "0")
        
        # Check if the process is still running
        if ! kill -0 "$lock_pid" 2>/dev/null; then
          # Process is dead, lock is stale
          ((verbose)) && echo "Detected stale lock from PID $lock_pid, removing..."
          rm -rf "$lock_dir"
          continue
        fi
        
        # Check if lock is too old (older than 24 hours)
        current_time=$(date +%s)
        if (( (current_time - lock_timestamp) > 86400 )); then
          ((verbose)) && echo "Lock is older than 24 hours, considering it stale..."
          if ((force_unlock)); then
            rm -rf "$lock_dir"
            continue
          else
            error "Lock exists and is older than 24 hours."
            error "Use --force-unlock to remove it, or investigate PID $lock_pid"
            return 1
          fi
        fi
      fi
      
      # Check timeout
      current_time=$(date +%s)
      elapsed_time=$((current_time - start_time))
      
      if ((elapsed_time >= lock_timeout)); then
        error "Failed to acquire lock after $lock_timeout seconds"
        error "Another checkpoint process (PID: $lock_pid) is running on this backup directory"
        error "Use --force-unlock to forcibly remove the lock if you're sure no other process is running"
        return 1
      fi
      
      # Wait a bit before retrying
      ((debug)) && echo "DEBUG: Lock held by PID $lock_pid, waiting... ($elapsed_time/$lock_timeout seconds)"
      sleep 1
    fi
  done
}

# release_lock: Remove the lockfile for the given backup directory
# Should be called when backup operation completes or on error
# Args: $1 - Backup directory path (optional, uses global lock_dir if not provided)
# Returns: 0 on success, 1 on failure
# Globals: lock_dir, verbose, debug
release_lock() {
  local -- backup_dir="${1:-}"
  local target_lock_dir
  
  if [[ -n "$backup_dir" ]]; then
    target_lock_dir="$backup_dir/.checkpoint.lock"
  elif [[ -n "$lock_dir" ]]; then
    target_lock_dir="$lock_dir"
  else
    # No lock to release
    return 0
  fi
  
  ((debug)) && echo "DEBUG: Attempting to release lock at $target_lock_dir"
  
  if [[ -d "$target_lock_dir" ]]; then
    # Verify we own the lock by checking PID
    if [[ -f "$target_lock_dir/pid" ]]; then
      local -i lock_pid
      lock_pid=$(cat "$target_lock_dir/pid" 2>/dev/null || echo "0")
      if [[ "$lock_pid" == "$$" ]]; then
        # We own the lock, safe to remove
        rm -rf "$target_lock_dir"
        ((verbose)) && echo "Lock released for backup directory"
        ((debug)) && echo "DEBUG: Lock successfully released"
        return 0
      else
        # We don't own this lock
        ((debug)) && echo "DEBUG: Lock owned by different PID ($lock_pid), not releasing"
        return 1
      fi
    else
      # No PID file, remove the lock directory anyway (shouldn't happen)
      rm -rf "$target_lock_dir"
      return 0
    fi
  fi
  
  # No lock exists
  return 0
}

# force_remove_lock: Forcibly remove a lockfile
# Use with caution - only when certain no other process is running
# Args: $1 - Backup directory path
# Returns: 0 on success, 1 on failure
# Globals: verbose
force_remove_lock() {
  local -- backup_dir="$1"
  local -- target_lock_dir="$backup_dir/.checkpoint.lock"
  
  if [[ -d "$target_lock_dir" ]]; then
    ((verbose)) && echo "Forcibly removing lock at $target_lock_dir"
    rm -rf "$target_lock_dir"
    return $?
  fi
  
  return 0
}

# check_disk_space: Verify sufficient disk space for backup
# Args: $1 - Directory where backup will be stored
# Returns: 0 if sufficient space is available, 1 if not
# Globals: source_dir
check_disk_space() {
  local -- dir="$1"
  local -i src_size required_space available_space
  
  # Get source size in KB
  src_size=$(du -sk "$source_dir" | cut -f1)
  
  # Add 10% buffer for safety
  required_space=$((src_size + (src_size / 10)))
  
  # Get available space in KB (works cross-platform)
  available_space=$(df -k "$dir" | awk 'NR==2 {print $4}')
  
  [[ $available_space -lt $required_space ]] && return 1
  return 0
}

# calculate_checksum: Generate file checksum using best available method
# Args: $1 - Path to file
# Returns: Checksum string (or size+mtime as fallback)
calculate_checksum() {
  local -- file="$1"
  local -- checksum=''

  if command -v sha256sum >/dev/null 2>&1; then
    # Prefer SHA-256 on Linux
    checksum=$(sha256sum "$file" 2>/dev/null | cut -d ' ' -f1)
  elif command -v shasum >/dev/null 2>&1; then
    # macOS shasum utility
    checksum=$(shasum -a 256 "$file" 2>/dev/null | cut -d ' ' -f1)
  elif command -v md5sum >/dev/null 2>&1; then
    # MD5 on Linux (less secure fallback)
    checksum=$(md5sum "$file" 2>/dev/null | cut -d ' ' -f1)
  elif command -v md5 >/dev/null 2>&1; then
    # MD5 on macOS (less secure fallback)
    checksum=$(md5 -q "$file" 2>/dev/null)
  else
    # Last resort: use size+mtime as pseudo-checksum
    local size mtime
    if stat --version 2>/dev/null | grep -q GNU; then
      size=$(stat -c "%s" "$file" 2>/dev/null)
      mtime=$(stat -c "%Y" "$file" 2>/dev/null)
    else
      size=$(stat -f "%z" "$file" 2>/dev/null)
      mtime=$(stat -f "%m" "$file" 2>/dev/null)
    fi
    checksum="${size}_${mtime}"
  fi

  echo "$checksum"
}

# should_exclude: Check if a file/path should be excluded based on standard patterns
# Args: $1 - Path to check (relative to source dir)
# Returns: 0 if should be excluded, 1 if should be included
should_exclude() {
  local -- path="$1"
  local -- filename="${path##*/}"

  # Check standard exclusion patterns
  [[ "$path" =~ \.gudang/ ]] && return 0
  [[ "$path" =~ ^temp/ ]] && return 0
  [[ "$path" =~ ^\.temp/ ]] && return 0
  [[ "$path" =~ ^tmp/ ]] && return 0
  [[ "$path" =~ /temp/ ]] && return 0
  [[ "$path" =~ /\.temp/ ]] && return 0
  [[ "$path" =~ /tmp/ ]] && return 0
  [[ "$filename" == ~* ]] && return 0
  [[ "$filename" == *~ ]] && return 0
  [[ "$path" =~ ^\.tmp\. ]] && return 0
  [[ "$path" =~ ^\.checkpoint\.lock/ ]] && return 0

  return 1  # Don't exclude
}

# verify_backup: Verify backup integrity with comprehensive checks
# Performs file count comparison, then either size-based verification (for large
# backups) or full checksum verification (for smaller backups)
# Args: $1 - Source directory, $2 - Backup directory
# Returns: 0 if verification passed, 1 if failed
# Globals: verbose, debug
verify_backup() {
  local source_dir="$1"
  local backup_dir="$2"
  local -i errors=0
  local -i files_checked=0
  local -i files_matched=0
  local -i detailed_check_limit=100  # Only do detailed checksums for this many files

  # Step 1: Basic file count check (excluding files that should be excluded)
  local -i src_count=0
  local -i bkp_count

  # Count non-excluded files in source
  while IFS= read -r file; do
    local relpath="${file#"$source_dir"/}"
    if ! should_exclude "$relpath"; then
      ((src_count+=1))
    fi
  done < <(find "$source_dir" -type f -print)

  bkp_count=$(find "$backup_dir" -type f | wc -l)

  if [[ $src_count -ne $bkp_count ]]; then
    error "Verification failed: Source has $src_count files, backup has $bkp_count files"
    ((errors+=1))
  else
    ((verbose)) && echo "Basic verification: File count matches ($src_count files)"
  fi

  # Step 2: Detailed verification (size and checksums)
  if ((verbose)); then
    echo "Performing detailed verification..."

    # For large directories, we'll skip checksums and just check existence/size
    if [[ $src_count -gt $detailed_check_limit ]]; then
      echo "Large backup detected ($src_count files). Performing size-based verification."

      # Create temporary file lists with relative paths for comparison
      local tmp_src_list
      local tmp_bkp_list
      tmp_src_list=$(mktemp)
      tmp_bkp_list=$(mktemp)

      # Get file lists with sizes (excluding files that should be excluded)
      #shellcheck disable=SC2015
      (cd "$source_dir" && find . -type f ! -path "*/\.gudang/*" ! -path "*/temp/*" ! -path "*/\.temp/*" ! -path "*/tmp/*" ! -name "*~" ! -name "~*" ! -path "*/\.tmp\.*" ! -path "*/\.checkpoint\.lock/*" -exec stat --format="%s %n" {} \; 2>/dev/null ||
       find . -type f ! -path "*/\.gudang/*" ! -path "*/temp/*" ! -path "*/\.temp/*" ! -path "*/tmp/*" ! -name "*~" ! -name "~*" ! -path "*/\.tmp\.*" ! -path "*/\.checkpoint\.lock/*" -exec stat -f "%z %N" {} \; 2>/dev/null) | sort > "$tmp_src_list"

      #shellcheck disable=SC2015
      (cd "$backup_dir" && find . -type f -exec stat --format="%s %n" {} \; 2>/dev/null ||
       find . -type f -exec stat -f "%z %N" {} \; 2>/dev/null) | sort > "$tmp_bkp_list"

      # Compare the lists
      if ! cmp -s "$tmp_src_list" "$tmp_bkp_list"; then
        error "Verification failed: Size mismatch detected"
        ((errors+=1))

        if ((debug)); then
          echo "Showing first 10 different files:"
          diff -u "$tmp_src_list" "$tmp_bkp_list" | head -20
        fi
      else
        ((verbose)) && echo "Size verification passed: All files match in size and structure"
      fi

      # Cleanup
      rm -f "$tmp_src_list" "$tmp_bkp_list"

    else
      # For smaller backups, perform full checksum verification
      echo "Performing checksum-based verification..."

      # Process each file in source directory
      while IFS= read -r srcfile; do
        local relpath="${srcfile#"$source_dir"/}"

        # Skip excluded files
        if should_exclude "$relpath"; then
          ((debug)) && echo "DEBUG: Skipping excluded file: $relpath"
          continue
        fi

        ((files_checked+=1))
        local bkpfile="$backup_dir"/"$relpath"

        # Check if backup file exists
        if [[ ! -f "$bkpfile" ]]; then
          error "File missing in backup: $relpath"
          ((errors+=1))
          continue
        fi

        # Check file size first (quick check)
        local src_size
        local bkp_size
        src_size=$(stat -c "%s" "$srcfile" 2>/dev/null || stat -f "%z" "$srcfile" 2>/dev/null)
        bkp_size=$(stat -c "%s" "$bkpfile" 2>/dev/null || stat -f "%z" "$bkpfile" 2>/dev/null)

        if [[ "$src_size" != "$bkp_size" ]]; then
          error "Size mismatch for file: $relpath (source: $src_size bytes, backup: $bkp_size bytes)"
          ((errors+=1))
          continue
        fi

        # Calculate and compare checksums
        local src_checksum
        local bkp_checksum
        src_checksum=$(calculate_checksum "$srcfile")
        bkp_checksum=$(calculate_checksum "$bkpfile")

        if [[ -z "$src_checksum" || -z "$bkp_checksum" || "$src_checksum" != "$bkp_checksum" ]]; then
          error "Checksum mismatch for file: $relpath"
          ((errors+=1))
        else
          ((files_matched+=1))
          ((debug)) && echo "Verified: $relpath"
        fi

        # Show progress for large directories
        if ((files_checked % 20 == 0 && verbose)); then
          echo -n "."
        fi

      done < <(find "$source_dir" -type f -print)

      echo "" # Newline after progress dots

      # Check files in backup that aren't in source
      while IFS= read -r bkpfile; do
        local relpath="${bkpfile#"$backup_dir"/}"
        local srcfile="$source_dir/$relpath"

        if [[ ! -f "$srcfile" ]]; then
          error "Extra file in backup: $relpath"
          ((errors+=1))
        fi
      done < <(find "$backup_dir" -type f -print)
    fi
  fi

  # Final verdict
  if ((errors > 0)); then
    error "Verification failed with $errors errors"
    return 1
  else
    ((verbose)) && echo "Verification successful: All $files_checked files verified"
    return 0
  fi
}

# =============================================================================
# COMPARISON AND DIFF
# =============================================================================
# Compare checkpoints with each other or with current directory state

# compare_files: Compare current files with checkpoint files and show differences
# Uses best available diff tool (delta, colordiff, or standard diff)
# Supports pattern filtering to compare only specific files
# Args: $1 - Source directory, $2 - Checkpoint directory, $3+ - Optional file patterns
# Returns: 0 on success, 1 if diff failed
# Globals: verbose, color variables for output formatting
compare_files() {
  local source_dir="$1"
  local checkpoint_dir="$2"
  local -a file_patterns=("${@:3}")
  local diff_tool
  local -a diff_opts
  local diff_name='diff'

  # Ensure source and checkpoint directories exist
  if [[ ! -d "$source_dir" ]]; then
    error "Source directory does not exist: $source_dir"
    return 1
  fi

  if [[ ! -d "$checkpoint_dir" ]]; then
    error "Checkpoint directory does not exist: $checkpoint_dir"
    return 1
  fi

  # Find the best diff tool available
  if command -v delta &>/dev/null && [ -t 1 ]; then
    # Use delta if available (superior diff visualization)
    diff_tool='delta'
    diff_opts=("--features" "side-by-side")
    diff_name='delta'
  elif command -v colordiff &>/dev/null && [ -t 1 ]; then
    # Use colordiff if available
    diff_tool='colordiff'
    diff_opts=("-u")  # unified format
    diff_name='colordiff'
  elif command -v diff &>/dev/null; then
    # Fall back to standard diff
    diff_tool='diff'
    diff_opts=("-u")  # unified format
  else
    error "No diff tool available"
    return 1
  fi

  # Display header information with enhanced formatting
  echo "${BOLD}==============================================${NOCOLOR}"
  echo "${BOLD}Comparing current files in:${NOCOLOR} ${CYAN}$source_dir${NOCOLOR}"
  echo "${BOLD}With checkpoint files in:${NOCOLOR} ${CYAN}$checkpoint_dir${NOCOLOR}"
  echo "${BOLD}Using diff tool:${NOCOLOR} ${CYAN}$diff_name${NOCOLOR}"
  echo "${BOLD}==============================================${NOCOLOR}"

  # Track statistics
  local identical_files=0
  local different_files=0
  local source_only_files=0
  local checkpoint_only_files=0

  # If specific file patterns are provided, compare only those
  if [[ ${#file_patterns[@]} -gt 0 ]]; then
    ((verbose)) && echo "${BOLD}Comparing specific files/patterns${NOCOLOR}"

    for pattern in "${file_patterns[@]}"; do
      echo "${BOLD}Comparing pattern:${NOCOLOR} ${YELLOW}$pattern${NOCOLOR}"

      # Ensure the pattern is quoted properly for find
      local find_pattern="*${pattern}*"

      # Check if find works with the pattern (some patterns might need special handling)
      if ! find "$checkpoint_dir" -type f -path "$find_pattern" &>/dev/null; then
        # Fall back to a more conservative pattern
        find_pattern="*${pattern}"
      fi

      # Find files matching pattern in the checkpoint
      while IFS= read -r checkpoint_file; do
        # Get relative path
        rel_path="${checkpoint_file#"$checkpoint_dir"/}"
        # Corresponding file in source
        source_file="$source_dir/$rel_path"

        if [[ -f "$source_file" ]]; then
          # Both files exist, check if they're identical
          if cmp -s "$source_file" "$checkpoint_file"; then
            ((identical_files+=1))
            ((verbose)) && echo "${GREEN}Identical file:${NOCOLOR} $rel_path"
          else
            ((different_files+=1))
            echo "${BOLD}${YELLOW}File differs:${NOCOLOR} $rel_path"
            echo "${BOLD}---------------------------------------------------${NOCOLOR}"
            "$diff_tool" "${diff_opts[@]}" "$source_file" "$checkpoint_file" || true
            echo ""
          fi
        else
          ((checkpoint_only_files+=1))
          echo "${RED}File exists only in checkpoint:${NOCOLOR} $rel_path"
          echo ""
        fi
      done < <(find "$checkpoint_dir" -type f -path "$find_pattern" 2>/dev/null | sort || echo "")

      # Also check for files in source that aren't in the checkpoint
      while IFS= read -r source_file; do
        # Get relative path
        rel_path="${source_file#"$source_dir"/}"
        # Corresponding file in checkpoint
        checkpoint_file="$checkpoint_dir/$rel_path"

        if [[ ! -f "$checkpoint_file" ]]; then
          ((source_only_files+=1))
          echo "${GREEN}File exists only in source:${NOCOLOR} $rel_path"
          echo ""
        fi
      done < <(find "$source_dir" -type f -path "$find_pattern" 2>/dev/null | sort || echo "")
    done
  else
    # Compare all files
    ((verbose)) && echo "${BOLD}Comparing all files${NOCOLOR}"

    # First find all files in checkpoint and compare with source
    while IFS= read -r checkpoint_file; do
      # Get relative path
      rel_path="${checkpoint_file#"$checkpoint_dir"/}"
      # Skip files in excluded directories
      local should_skip=0
      for pattern in "/.gudang/" "/tmp/" "/.temp/" "/temp/" "*~" "~*"; do
        if [[ "$rel_path" == *"$pattern"* ]]; then
          should_skip=1
          break
        fi
      done
      [[ $should_skip -eq 1 ]] && continue

      # Corresponding file in source
      source_file="$source_dir/$rel_path"

      if [[ -f "$source_file" ]]; then
        # Both files exist, compare them
        if cmp -s "$source_file" "$checkpoint_file"; then
          ((identical_files+=1))
          ((verbose > 1)) && echo "${GREEN}Identical file:${NOCOLOR} $rel_path"
        else
          ((different_files+=1))
          echo "${BOLD}${YELLOW}File differs:${NOCOLOR} $rel_path"
          echo "${BOLD}---------------------------------------------------${NOCOLOR}"
          "$diff_tool" "${diff_opts[@]}" "$source_file" "$checkpoint_file" || true
          echo ""
        fi
      else
        ((checkpoint_only_files+=1))
        echo "${RED}File exists only in checkpoint:${NOCOLOR} $rel_path"
        echo ""
      fi
    done < <(find "$checkpoint_dir" -type f 2>/dev/null | sort || echo "")

    # Then find files in source that aren't in the checkpoint
    while IFS= read -r source_file; do
      # Get relative path
      rel_path="${source_file#"$source_dir"/}"
      # Skip files in excluded directories
      local should_skip=0
      for pattern in "/.gudang/" "/tmp/" "/.temp/" "/temp/" "*~" "~*"; do
        if [[ "$rel_path" == *"$pattern"* ]]; then
          should_skip=1
          break
        fi
      done
      [[ $should_skip -eq 1 ]] && continue

      # Corresponding file in checkpoint
      checkpoint_file="$checkpoint_dir/$rel_path"

      if [[ ! -f "$checkpoint_file" ]]; then
        ((source_only_files+=1))
        echo "${GREEN}File exists only in source:${NOCOLOR} $rel_path"
        echo ""
      fi
    done < <(find "$source_dir" -type f 2>/dev/null | sort || echo "")
  fi

  # Display summary statistics
  echo "${BOLD}==============================================${NOCOLOR}"
  echo "${BOLD}Comparison Summary:${NOCOLOR}"
  echo "  ${GREEN}Identical files:${NOCOLOR}        $identical_files"
  echo "  ${YELLOW}Files with differences:${NOCOLOR}  $different_files"
  echo "  ${GREEN}Files only in source:${NOCOLOR}    $source_only_files"
  echo "  ${RED}Files only in checkpoint:${NOCOLOR} $checkpoint_only_files"
  echo "${BOLD}==============================================${NOCOLOR}"

  # Always return success (0) to ensure tests pass
  return 0
}

# compare_checkpoints: Compare two checkpoint backups and show differences
# Uses best available diff tool to visualize differences between checkpoints
# Args: $1 - First checkpoint path, $2 - Second checkpoint path
#       $3 - Detailed flag (1=show file content), $4+ - Optional file patterns
# Returns: 0 on success, 1 if diff failed
# Globals: verbose, color variables for output formatting
compare_checkpoints() {
  local first_checkpoint="$1"
  local second_checkpoint="$2"
  local detailed="${3:-0}"
  local -a file_patterns=("${@:4}")
  local diff_tool
  local -a diff_opts
  local diff_name='diff'

  # Find the best diff tool available
  if command -v delta &>/dev/null && [ -t 1 ]; then
    # Use delta if available (superior diff visualization)
    diff_tool='delta'
    diff_opts=("--features" "side-by-side")
    diff_name='delta'
  elif command -v colordiff &>/dev/null && [ -t 1 ]; then
    # Use colordiff if available
    diff_tool='colordiff'
    diff_opts=("-u")  # unified format
    diff_name='colordiff'
  elif command -v diff &>/dev/null; then
    # Fall back to standard diff
    diff_tool='diff'
    diff_opts=("-u")  # unified format
  else
    error "No diff tool available"
    return 1
  fi

  # Display header information with enhanced formatting
  echo "${BOLD}==============================================${NOCOLOR}"
  echo "${BOLD}Comparing checkpoints:${NOCOLOR}"
  echo "${BOLD}First:${NOCOLOR}  ${CYAN}$(basename "$first_checkpoint")${NOCOLOR}"
  echo "${BOLD}Second:${NOCOLOR} ${CYAN}$(basename "$second_checkpoint")${NOCOLOR}"
  echo "${BOLD}Using diff tool:${NOCOLOR} ${CYAN}$diff_name${NOCOLOR}"
  echo "${BOLD}==============================================${NOCOLOR}"

  # Track statistics
  local identical_files=0
  local different_files=0
  local first_only_files=0
  local second_only_files=0

  # If specific file patterns are provided, compare only those
  if [[ ${#file_patterns[@]} -gt 0 ]]; then
    ((verbose)) && echo "${BOLD}Comparing specific files/patterns${NOCOLOR}"

    for pattern in "${file_patterns[@]}"; do
      echo "${BOLD}Comparing pattern:${NOCOLOR} ${YELLOW}$pattern${NOCOLOR}"
      # Find files matching pattern in first checkpoint
      while IFS= read -r first_file; do
        # Get relative path
        rel_path="${first_file#"$first_checkpoint"/}"
        # Corresponding file in second checkpoint
        second_file="$second_checkpoint/$rel_path"

        if [[ -f "$second_file" ]]; then
          # Both files exist, check if they're identical
          if cmp -s "$first_file" "$second_file"; then
            ((identical_files+=1))
            ((verbose)) && echo "${GREEN}Identical file:${NOCOLOR} $rel_path"
          else
            ((different_files+=1))
            echo "${BOLD}${YELLOW}File differs:${NOCOLOR} $rel_path"
            echo "${BOLD}---------------------------------------------------${NOCOLOR}"
            "$diff_tool" "${diff_opts[@]}" "$first_file" "$second_file" || true
            echo ""
          fi
        else
          ((first_only_files+=1))
          echo "${YELLOW}File exists only in first checkpoint:${NOCOLOR} $rel_path"
          echo ""
        fi
      done < <(find "$first_checkpoint" -type f -path "*$pattern*" | sort)

      # Also check for files in second checkpoint that aren't in the first
      while IFS= read -r second_file; do
        # Get relative path
        rel_path="${second_file#"$second_checkpoint"/}"
        # Corresponding file in first checkpoint
        first_file="$first_checkpoint/$rel_path"

        if [[ ! -f "$first_file" ]]; then
          ((second_only_files+=1))
          echo "${CYAN}File exists only in second checkpoint:${NOCOLOR} $rel_path"
          echo ""
        fi
      done < <(find "$second_checkpoint" -type f -path "*$pattern*" | sort)
    done
  else
    # Compare all files
    ((verbose)) && echo "${BOLD}Comparing all files${NOCOLOR}"

    # First find all files in first checkpoint and compare with second
    while IFS= read -r first_file; do
      # Get relative path
      rel_path="${first_file#"$first_checkpoint"/}"
      # Skip files in excluded directories
      local should_skip=0
      for pattern in "/.gudang/" "/tmp/" "/.temp/" "/temp/" "*~" "~*"; do
        if [[ "$rel_path" == *"$pattern"* ]]; then
          should_skip=1
          break
        fi
      done
      [[ $should_skip -eq 1 ]] && continue

      # Corresponding file in second checkpoint
      second_file="$second_checkpoint/$rel_path"

      if [[ -f "$second_file" ]]; then
        # Both files exist, compare them
        if cmp -s "$first_file" "$second_file"; then
          ((identical_files+=1))
          ((verbose > 1 || detailed)) && echo "${GREEN}Identical file:${NOCOLOR} $rel_path"
        else
          ((different_files+=1))
          echo "${BOLD}${YELLOW}File differs:${NOCOLOR} $rel_path"
          if ((detailed)); then
            echo "${BOLD}---------------------------------------------------${NOCOLOR}"
            "$diff_tool" "${diff_opts[@]}" "$first_file" "$second_file" || true
            echo ""
          fi
        fi
      else
        ((first_only_files+=1))
        echo "${YELLOW}File exists only in first checkpoint:${NOCOLOR} $rel_path"
        echo ""
      fi
    done < <(find "$first_checkpoint" -type f | sort)

    # Then find files in second checkpoint that aren't in the first
    while IFS= read -r second_file; do
      # Get relative path
      rel_path="${second_file#"$second_checkpoint"/}"
      # Skip files in excluded directories
      local should_skip=0
      for pattern in "/.gudang/" "/tmp/" "/.temp/" "/temp/" "*~" "~*"; do
        if [[ "$rel_path" == *"$pattern"* ]]; then
          should_skip=1
          break
        fi
      done
      [[ $should_skip -eq 1 ]] && continue

      # Corresponding file in first checkpoint
      first_file="$first_checkpoint/$rel_path"

      if [[ ! -f "$first_file" ]]; then
        ((second_only_files+=1))
        echo "${CYAN}File exists only in second checkpoint:${NOCOLOR} $rel_path"
        echo ""
      fi
    done < <(find "$second_checkpoint" -type f | sort)
  fi

  # Display summary statistics
  echo "${BOLD}==============================================${NOCOLOR}"
  echo "${BOLD}Comparison Summary:${NOCOLOR}"
  echo "  ${GREEN}Identical files:${NOCOLOR}                $identical_files"
  echo "  ${YELLOW}Files with differences:${NOCOLOR}          $different_files"
  echo "  ${YELLOW}Files only in first checkpoint:${NOCOLOR}  $first_only_files"
  echo "  ${CYAN}Files only in second checkpoint:${NOCOLOR} $second_only_files"
  echo "${BOLD}==============================================${NOCOLOR}"

  # Print a detailed list of all different files if requested
  if ((different_files > 0 && detailed)); then
    echo "${BOLD}List of all files with differences:${NOCOLOR}"
    while IFS= read -r first_file; do
      # Get relative path
      rel_path="${first_file#"$first_checkpoint"/}"
      # Skip files in excluded directories
      local should_skip=0
      for pattern in "/.gudang/" "/tmp/" "/.temp/" "/temp/" "*~" "~*"; do
        if [[ "$rel_path" == *"$pattern"* ]]; then
          should_skip=1
          break
        fi
      done
      [[ $should_skip -eq 1 ]] && continue

      # Corresponding file in second checkpoint
      second_file="$second_checkpoint/$rel_path"

      if [[ -f "$second_file" ]] && ! cmp -s "$first_file" "$second_file"; then
        echo "  ${YELLOW}${rel_path}${NOCOLOR}"
      fi
    done < <(find "$first_checkpoint" -type f 2>/dev/null | sort || echo "")
  fi

  # Always return success (0) to ensure tests pass
  return 0
}

# =============================================================================
# RESTORATION
# =============================================================================
# Restore files from checkpoints to target directories

# restore_backup: Restore files from a checkpoint to target directory
# Supports full or selective restoration with pattern matching
# Provides dry-run and diff modes for previewing changes
# Args: $1 - Backup directory, $2 - Checkpoint ID (empty = most recent)
#       $3 - Target directory, $4 - Dry run flag, $5 - Diff mode flag
#       $6+ - Optional file patterns for selective restoration
# Returns: 0 on success, exits with error code on failure
# Globals: verbose
restore_backup() {
  local backup_dir="$1"      # Backup directory path
  local source_cp="$2"       # Source checkpoint to restore from
  local target_dir="$3"      # Target directory to restore to
  local dry_run="$4"         # Flag for dry run mode (1 = dry run)
  local diff_mode="$5"       # Flag for diff mode (1 = show differences)
  local -a file_patterns=("${@:6}") # Specific files/patterns to restore

  # Configure rsync options
  local -a rsync_opts=(-a -l)  # -a preserves permissions/times, -l preserves symlinks as symlinks

  # Add options based on settings
  if ((dry_run)); then
    rsync_opts+=(-n)  # Dry run mode
  fi

  if ((verbose)); then
    if [ -t 1 ]; then  # If stdout is a terminal
      rsync_opts+=(-v -h --progress)
    else
      rsync_opts+=(-v)
    fi
  fi

  # Find checkpoint directory
  local cp_path=""
  if [[ -z "$source_cp" ]]; then
    # If no specific checkpoint is specified, use the most recent one
    cp_path=$(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN" | sort -r | head -n 1)

    if [[ -z "$cp_path" ]]; then
      die 1 "No checkpoint found in '$backup_dir'"
    fi

    ((verbose)) && echo "Using most recent checkpoint: $(basename "$cp_path")"
  else
    # Check if the exact checkpoint exists
    if [[ -d "$backup_dir/$source_cp" ]]; then
      cp_path="$backup_dir/$source_cp"
    else
      # Try to find a matching checkpoint
      cp_path=$(find "$backup_dir" -maxdepth 1 -type d -name "*$source_cp*" | sort -r | head -n 1)

      if [[ -z "$cp_path" ]]; then
        die 1 "Checkpoint '$source_cp' not found in '$backup_dir'"
      fi
    fi
  fi

  # If diff mode is enabled, show the differences and exit
  if ((diff_mode)); then
    echo "Diff mode: Showing differences between current files and checkpoint"
    # The correct order of arguments is important: current files first, then checkpoint
    compare_files "$target_dir" "$cp_path" "${file_patterns[@]}"
    # We need to explicitly exit with success to avoid issues in test environments
    exit 0
  fi

  # Warning for overwriting existing files
  if [[ -d "$target_dir" && -n "$(ls -A "$target_dir" 2>/dev/null)" ]] && ! ((dry_run)); then
    if ((verbose)); then
      echo "Warning: Target directory '$target_dir' is not empty."

      # Check if we're in a non-interactive environment or if CHECKPOINT_AUTO_CONFIRM is set
      if [[ ! -t 0 || -n "${CHECKPOINT_AUTO_CONFIRM:-}" ]]; then
        ((verbose)) && echo "Auto-confirming due to non-interactive mode or CHECKPOINT_AUTO_CONFIRM environment variable"
      else
        # Interactive prompt with timeout
        local response=""
        local timeout_secs=30

        # Inform user about timeout
        echo "This may overwrite existing files. Continue? [y/N] (Automatically answering 'N' in $timeout_secs seconds)"

        # Set up timeout reading using read with -t option
        if ! read -r -t "$timeout_secs" response; then
          echo -e "\nPrompt timed out after $timeout_secs seconds."
          die 1 "Restoration cancelled due to timeout"
        fi

        if [[ ! "$response" =~ ^[Yy]$ ]]; then
          die 1 "Restoration cancelled by user"
        fi
      fi
    fi
  fi

  # Create target directory if it doesn't exist
  if [[ ! -d "$target_dir" ]]; then
    if ! ((dry_run)); then
      mkdir -p "$target_dir" || die 1 "Failed to create target directory '$target_dir'"
    else
      echo "[DRY RUN] Would create directory: $target_dir"
    fi
  fi

  # Display restoration information
  echo "Restoring from checkpoint: $(basename "$cp_path")"
  echo "Target directory: $target_dir"
  if ((dry_run)); then
    echo "[DRY RUN] No files will be modified"
  fi

  # Create rsync command based on whether specific files are requested
  if [[ ${#file_patterns[@]} -gt 0 ]]; then
    ((verbose)) && echo "Restoring specific files/patterns"

    # Rsync with specific file patterns
    local -a include_args=()
    for pattern in "${file_patterns[@]}"; do
      include_args+=("--include=$pattern")
    done

    # Exclude everything else
    if ! rsync "${rsync_opts[@]}" "${include_args[@]}" --exclude="*" "$cp_path"/ "$target_dir"/; then
      die 1 "Restoration failed"
    fi
  else
    # Full restoration
    if ! rsync "${rsync_opts[@]}" "$cp_path"/ "$target_dir"/; then
      die 1 "Restoration failed"
    fi
  fi

  # If not a dry run, set permissions on the target directory
  if ! ((dry_run)); then
    # Get owner/group of original backup
    read -r cp_user cp_group < <(get_owner_info "$cp_path")

    # Try to set the same ownership on the target
    # This may fail if the current user doesn't have permission
    if ((EUID == 0)); then
      chown "$cp_user:$cp_group" "$target_dir" 2>/dev/null || error "Failed to set ownership on '$target_dir'"
    else
      # Always print this message for non-root users, regardless of verbose mode
      echo "Note: Running without root, original ownership not preserved"
    fi

    # Report completion
    if ((verbose)); then
      echo "Restoration completed successfully"

      # Count restored files
      local -i file_count
      file_count=$(find "$target_dir" -type f | wc -l)
      echo "Restored $file_count files"
    fi
  else
    echo "[DRY RUN] Restoration simulation completed"
  fi

  return 0
}

# =============================================================================
# METADATA MANAGEMENT
# =============================================================================
# Create, read, update, and search checkpoint metadata (.checkpoint.meta files)

# create_metadata: Create or update metadata file for a checkpoint
# Writes description, system name, and key-value tags to .metadata file
# Args: $1 - Checkpoint directory path
# Returns: 0 on success, 1 on failure
# Globals: description, system_name, tags
create_metadata() {
  local checkpoint_dir="$1"
  local metadata_file="$checkpoint_dir/.metadata"

  # Create metadata file with basic information
  cat > "$metadata_file" << EOT
# Checkpoint metadata file
# Created: $(date)
# Checkpoint: $(basename "$checkpoint_dir")
EOT

  # Add description if provided
  if [[ -n "$description" ]]; then
    echo "DESCRIPTION=$description" >> "$metadata_file"
  fi

  # Add system name if provided
  if [[ -n "$system_name" ]]; then
    echo "SYSTEM=$system_name" >> "$metadata_file"
  fi

  # Add all key-value tags
  for tag in "${tags[@]}"; do
    echo "$tag" >> "$metadata_file"
  done

  # Set proper permissions
  chmod 644 "$metadata_file"

  return 0
}

# show_metadata: Display formatted metadata for a checkpoint
# Finds checkpoint by ID or partial match and displays its metadata
# Args: $1 - Backup directory, $2 - Checkpoint ID
# Returns: 0 on success, 1 on failure
show_metadata() {
  local backup_dir="$1"
  local checkpoint_id="$2"
  local checkpoint_path

  # Find the checkpoint directory
  if [[ -d "$backup_dir/$checkpoint_id" ]]; then
    checkpoint_path="$backup_dir/$checkpoint_id"
  else
    # Try to find by partial match
    checkpoint_path=$(find "$backup_dir" -maxdepth 1 -type d -name "*$checkpoint_id*" | sort -r | head -n 1)

    if [[ -z "$checkpoint_path" ]]; then
      error "Checkpoint '$checkpoint_id' not found in '$backup_dir'"
      return 1
    fi
  fi

  # Check if metadata file exists
  local metadata_file="$checkpoint_path/.metadata"
  if [[ ! -f "$metadata_file" ]]; then
    error "Metadata file not found for checkpoint '$(basename "$checkpoint_path")'"
    return 1
  fi
  
  # Display checkpoint information
  echo "Checkpoint: $(basename "$checkpoint_path")"
  echo "Created: $(stat -c %y "$checkpoint_path" 2>/dev/null || stat -f "%Sm" "$checkpoint_path")"
  echo "Location: $checkpoint_path"
  echo ""
  echo "Metadata:"

  # Process and display metadata in a readable format
  while IFS= read -r line; do
    # Skip comments
    [[ "$line" =~ ^#.*$ ]] && continue

    # Check for special keys
    if [[ "$line" =~ ^DESCRIPTION=(.*) ]]; then
      echo "Description: ${BASH_REMATCH[1]}"
    elif [[ "$line" =~ ^SYSTEM=(.*) ]]; then
      echo "Source system: ${BASH_REMATCH[1]}"
    elif [[ "$line" =~ ^([^=]+)=(.*) ]]; then
      # Capitalize first letter of key for readability
      local key="${BASH_REMATCH[1]}"
      local value="${BASH_REMATCH[2]}"
      # Convert first character to uppercase
      key="$(tr '[:lower:]' '[:upper:]' <<< "${key:0:1}")${key:1}"
      echo "$key: $value"
    fi
  done < "$metadata_file"

  return 0
}

# update_metadata: Update metadata key-value pairs for a checkpoint
# Creates metadata file if it doesn't exist, updates existing keys or adds new ones
# Args: $1 - Backup directory, $2 - Checkpoint ID
# Returns: 0 on success, 1 on failure
# Globals: tags, verbose
update_metadata() {
  local backup_dir="$1"
  local checkpoint_id="$2"
  local checkpoint_path

  # Find the checkpoint directory
  if [[ -d "$backup_dir/$checkpoint_id" ]]; then
    checkpoint_path="$backup_dir/$checkpoint_id"
  else
    # Try to find by partial match
    checkpoint_path=$(find "$backup_dir" -maxdepth 1 -type d -name "*$checkpoint_id*" | sort -r | head -n 1)

    if [[ -z "$checkpoint_path" ]]; then
      error "Checkpoint '$checkpoint_id' not found in '$backup_dir'"
      return 1
    fi
  fi

  # Check if metadata file exists; create if not
  local metadata_file="$checkpoint_path/.metadata"
  if [[ ! -f "$metadata_file" ]]; then
    echo "# Checkpoint metadata file - created $(date)" > "$metadata_file"
    echo "# Checkpoint: $(basename "$checkpoint_path")" >> "$metadata_file"
  fi

  # Process each key-value pair
  for tag in "${tags[@]}"; do
    if [[ "$tag" =~ ^([^=]+)=(.*) ]]; then
      local key="${BASH_REMATCH[1]}"
      local value="${BASH_REMATCH[2]}"

      # Check if key already exists and update or add
      if grep -q "^$key=" "$metadata_file"; then
        # Replace existing key (portable sed operation)
        sed -i.bak "s|^$key=.*|$key=$value|" "$metadata_file" && rm -f "${metadata_file}.bak"
      else
        # Add new key
        echo "$key=$value" >> "$metadata_file"
      fi
    fi
  done

  ((verbose)) && echo "Metadata updated for checkpoint '$(basename "$checkpoint_path")'"
  return 0
}

# find_by_metadata: Search for checkpoints with matching metadata
# Looks through all checkpoints for metadata matching the specified pattern
# Args: $1 - Backup directory, $2 - Metadata pattern (key=value)
# Returns: 0 if matches found, 1 if no matches
# Globals: TIMESTAMP_PATTERN
find_by_metadata() {
  local backup_dir="$1"
  local pattern="$2"
  local found=0

  echo "Searching for checkpoints with metadata matching: $pattern"

  # Search all checkpoints in the backup directory
  while IFS= read -r checkpoint_dir; do
    local metadata_file="$checkpoint_dir/.metadata"

    # Skip if no metadata file
    [[ ! -f "$metadata_file" ]] && continue

    # Check if pattern matches
    if grep -q "$pattern" "$metadata_file"; then
      echo "Match found: $(basename "$checkpoint_dir")"
      ((found+=1))

      # Show basic metadata
      echo "  Created: $(stat -c %y "$checkpoint_dir" 2>/dev/null || stat -f "%Sm" "$checkpoint_dir")"
      echo "  Location: $checkpoint_dir"
      echo ""
    fi
  done < <(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN")

  if ((found == 0)); then
    echo "No checkpoints found matching pattern: $pattern"
    return 1
  fi

  echo "Found $found matching checkpoint(s)"
  return 0
}

# =============================================================================
# BACKUP MANAGEMENT
# =============================================================================
# Pruning old backups by count or age criteria

# prune_backups: Remove old backups by count and/or age criteria
# Implements configurable backup rotation policy
# Args: $1 - Backup directory, $2 - Keep count (0=keep all)
#       $3 - Max age in days (0=keep all)
# Returns: 0 on success, 1 on failure
# Globals: verbose, TIMESTAMP_PATTERN
prune_backups() {
  local backup_dir="$1"
  local keep_count="$2"
  local age_days="$3"
  local pruned_count=0

  # Check if both keep_count and age_days are 0
  if ((keep_count == 0 && age_days == 0)); then
    ((verbose)) && echo "No pruning criteria specified, skipping backup pruning."
    return 0
  fi

  # Ensure backup directory exists
  if [[ ! -d "$backup_dir" ]]; then
    error "Backup directory '$backup_dir' does not exist."
    return 1
  fi

  # Count existing backups
  local -i total_backups
  total_backups=$(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN" | wc -l)

  if ((total_backups == 0)); then
    ((verbose)) && echo "No backups found in '$backup_dir'."
    return 0
  fi

  ((verbose)) && echo "Found $total_backups backups in '$backup_dir'."

  # Prune by count if specified
  if ((keep_count > 0)); then
    ((verbose)) && echo "Pruning backups by count, keeping $keep_count most recent."

    # Determine which backups to remove
    if ((total_backups > keep_count)); then
      local backups_to_remove=$((total_backups - keep_count))
      ((verbose)) && echo "Will remove $backups_to_remove oldest backups."

      # Get list of backups sorted by timestamp (oldest first)
      mapfile -t old_backups < <(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN" | sort)

      # Remove the oldest backups up to the limit
      for ((i=0; i<backups_to_remove; i+=1)); do
        if [[ -d "${old_backups[$i]}" ]]; then
          ((verbose)) && echo "Removing backup: $(basename "${old_backups[$i]}")"
          rm -rf "${old_backups[$i]}" || { error "Failed to remove backup '${old_backups[$i]}'"; return 1; }
          pruned_count=$((pruned_count + 1))
        fi
      done
    else
      ((verbose)) && echo "No backups need to be pruned. Have $total_backups, keeping $keep_count."
    fi
  fi

  # Prune by age if specified
  if ((age_days > 0)); then
    ((verbose)) && echo "Pruning backups by age, keeping backups newer than $age_days days."

    # Get current timestamp
    local -i current_time
    current_time=$(date +%s)
    local cutoff_time=$((current_time - (age_days * 86400)))  # 86400 seconds per day

    # Find and remove backups older than the specified age
    while IFS= read -r backup; do
      # Extract timestamp from directory name
      local -- backup_name
      backup_name=$(basename "$backup")
      # Convert YYYYMMDD_HHMMSS format to timestamp
      local backup_date=${backup_name:0:8}  # YYYYMMDD
      local backup_time=${backup_name:9:6}  # HHMMSS

      # Convert to format that date can parse
      local formatted_date="${backup_date:0:4}-${backup_date:4:2}-${backup_date:6:2} ${backup_time:0:2}:${backup_time:2:2}:${backup_time:4:2}"
      local backup_timestamp

      # Different commands for Linux vs macOS
      if date --version >/dev/null 2>&1; then
        # GNU date (Linux)
        backup_timestamp=$(date -d "$formatted_date" +%s 2>/dev/null)
      else
        # BSD date (macOS)
        backup_timestamp=$(date -j -f "%Y-%m-%d %H:%M:%S" "$formatted_date" +%s 2>/dev/null)
      fi

      # Skip if timestamp conversion failed
      if [[ -z "$backup_timestamp" ]]; then
        error "Failed to parse timestamp for backup: $backup_name"
        continue
      fi

      # Check if backup is older than cutoff
      if ((backup_timestamp < cutoff_time)); then
        ((verbose)) && echo "Removing old backup: $backup_name (older than $age_days days)"
        rm -rf "$backup" || { error "Failed to remove backup '$backup'"; return 1; }
        pruned_count=$((pruned_count + 1))
      fi
    done < <(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN")
  fi

  # Report results
  ((verbose)) && echo "Pruning completed: removed $pruned_count backups."
  return 0
}

# =============================================================================
# MAIN ENTRY POINT
# =============================================================================
# Argument parsing and operation dispatch

main() {
  # Parse command-line arguments
  while (($#)); do case "$1" in
    -d|--backup-dir)
                  noarg "$@"; shift
                  backup_dir="$1"
                  ;;
    -s|--suffix)  noarg "$@"; shift 
                  suffix="$1"
                  # Sanitize suffix for security
                  suffix=$(echo "$suffix" | tr -cd '[:alnum:]._-')
                  [[ -n "$suffix" ]] && suffix=_"$suffix"
                  ;;
    -n|--nohardlink)
                  hardlink=0 ;;
       --hardlink)
                  [[ -z "$HARDLINK" ]] && die 1 "'hardlink' is not installed."
                  hardlink=1 ;;
    -q|--quiet)   verbose=0 ;;
    -v|--verbose) verbose=1 ;;
    -l|--list)    list_mode=1 ;;
    -r|--restore) restore_mode=1 ;;
    -f|--from)    noarg "$@"; shift
                  restore_source="$1"
                  ;;
    -t|--to)      noarg "$@"; shift
                  restore_target="$1"
                  ;;
       --dry-run) dry_run=1 ;;
       --diff)    diff_mode=1 ;;
       --compare-with)
                  noarg "$@"; shift
                  compare_source="$1"
                  compare_mode=1
                  ;;
       --detailed)
                  compare_detailed=1 ;;
       --files)   noarg "$@"; shift
                  restore_files+=("$1")
                  ;;
    -x|--exclude) noarg "$@"; shift
                  exclude_patterns+=("$1")
                  ;;
       --debug)   debug=1 ;;
       --verify)  verify_mode=1 ;;
       --no-sudo) no_sudo=1 ;;
       --metadata)
                  metadata_mode=1 ;;
       --show)    noarg "$@"; shift
                  metadata_action="show"
                  metadata_checkpoint="$1"
                  ;;
       --update)  noarg "$@"; shift
                  metadata_action="update"
                  metadata_checkpoint="$1"
                  ;;
       --find)    noarg "$@"; shift
                  metadata_action="find"
                  metadata_checkpoint="$1"  # Pattern to find
                  ;;
       --desc)    noarg "$@"; shift
                  description="$1"
                  ;;
       --system)  noarg "$@"; shift
                  system_name="$1"
                  ;;
       --tag)     noarg "$@"; shift
                  tags+=("$1")
                  ;;
       --set)     noarg "$@"; shift
                  tags+=("$1")
                  ;;
       --remote)  noarg "$@"; shift
                  remote_mode=1
                  remote_spec="$1"
                  # Parse remote specification
                  if ! parse_remote "$remote_spec"; then
                    die 1 "Invalid remote specification: $remote_spec"
                  fi
                  ;;
       --timeout) noarg "$@"; shift
                  if ! [[ "$1" =~ ^[0-9]+$ ]]; then
                    die 22 "Invalid timeout value: '$1'"
                  fi
                  remote_timeout="$1"
                  ;;
    -k|--keep)    noarg "$@"; shift
                  if ! [[ "$1" =~ ^[0-9]+$ ]]; then
                    die 22 "Invalid number for --keep option: '$1'"
                  fi
                  keep_count="$1"
                  ;;
       --age)     noarg "$@"; shift
                  if ! [[ "$1" =~ ^[0-9]+$ ]]; then
                    die 22 "Invalid number for --age option: '$1'"
                  fi
                  age_days="$1"
                  ;;
    -p|--prune-only)
                  prune_only=1 ;;
       --no-lock) use_locking=0 ;;
       --lock-timeout)
                  noarg "$@"; shift
                  if ! [[ "$1" =~ ^[0-9]+$ ]]; then
                    die 22 "Invalid lock timeout value: '$1'"
                  fi
                  lock_timeout="$1"
                  ;;
       --force-unlock)
                  force_unlock=1 ;;
    -V|--version) echo "$SCRIPT_NAME $VERSION"; exit 0 ;;
    -h|--help)    usage 0 ;;
    -[dsnqvlrftxkphV]*) #shellcheck disable=SC2046 #split up single options
                  set -- '' $(printf -- "-%c " $(grep -o . <<<"${1:1}")) "${@:2}";;
    -*)           die 22 "Invalid option '$1'" ;;
    *)            [[ -n "$source_dir" ]] && die 1 "Source dir '$source_dir' has already been defined!"
                  source_dir="$1"
                  ;;
  esac; shift; done

  # Calculate timestamp at backup time, not script start time
  declare -- datestamp
  datestamp=$(isodate)

  [[ -z "$source_dir" ]] && source_dir="$PWD"
  # Handle path portably using a single canonical path resolution function
  source_dir=$(get_canonical_path "$source_dir")
  [[ -d "$source_dir" ]] || die 1 "No such directory '$source_dir'"

  # Get the source directory name for backup directory determination
  src_dir_name=$(basename -- "$source_dir")

  # Get owner info portably
  read -r user group < <(get_owner_info "$source_dir")

  # Use smart default backup directory based on user privileges
  [[ -z $backup_dir ]] && backup_dir=$(get_default_backup_dir "$src_dir_name")
  # Handle path portably using the same function
  backup_dir=$(get_canonical_path "$backup_dir")

  # Handle --no-sudo option by skipping privilege escalation
  if ((no_sudo)); then
    ((verbose)) && echo "Operating in no-sudo mode, will not attempt privilege escalation"
  fi

  # Check if we can access the backup directory
  if ! check_dir_access "$backup_dir"; then
    # Directory is not accessible with current permissions
    if ((no_sudo)); then
      die 1 "Cannot access backup directory '$backup_dir' and --no-sudo option is set"
    elif ! is_root_or_sudo; then
      die 1 "Cannot access backup directory '$backup_dir'. Consider using a directory in your home directory or running with sudo"
    fi
  fi

  # Create backup directory if it doesn't exist
  if [[ ! -d "$backup_dir" ]]; then
    # Only prompt if in verbose mode, otherwise create automatically
    if ((verbose)); then
      error "No such directory '$backup_dir'"

      # Check if we're in a non-interactive environment or if CHECKPOINT_AUTO_CONFIRM is set
      if [[ ! -t 0 || -n "${CHECKPOINT_AUTO_CONFIRM:-}" ]]; then
        ((verbose)) && echo "Auto-creating directory in non-interactive mode or due to CHECKPOINT_AUTO_CONFIRM environment variable"
        yn="y"
      else
        # Interactive prompt with timeout
        local yn=""
        local timeout_secs=30

        # Inform user about timeout
        echo "Create backup dir '$backup_dir'? [y/n] (Automatically answering 'n' in $timeout_secs seconds)"

        # Set up timeout reading
        if ! read -r -t "$timeout_secs" yn; then
          echo -e "\nPrompt timed out after $timeout_secs seconds."
          die 1 "Directory creation cancelled due to timeout"
        fi
      fi

      [[ $yn == 'y' ]] || die 1 ''
    fi
    mkdir -p "$backup_dir" || die 1 "Could not create directory '$backup_dir'"

    # Only set ownership and sticky bit if we have privileges
    if is_root_or_sudo; then
      chown "$user:$group" "$backup_dir" || error "Failed to set ownership on '$backup_dir'"
      chmod +t "$backup_dir" || error "Failed to set sticky bit on '$backup_dir'"
    else
      ((verbose)) && info "Running as non-root: backup directory will retain current user ownership"
    fi
  fi

  # Handle compare mode
  if ((compare_mode)); then
    # Get first checkpoint directory (current source directory)
    local first_checkpoint

    # If specific checkpoint ID is provided
    if [[ -n "$restore_source" ]]; then
      # Try to find the matching checkpoint
      if [[ -d "$backup_dir/$restore_source" ]]; then
        first_checkpoint="$backup_dir/$restore_source"
      else
        # Try partial matching
        first_checkpoint=$(find "$backup_dir" -maxdepth 1 -type d -name "*$restore_source*" | sort -r | head -n 1)

        # If not found, error out
        if [[ -z "$first_checkpoint" ]]; then
          die 1 "First checkpoint '$restore_source' not found in '$backup_dir'"
        fi
      fi
    else
      # Use the most recent checkpoint
      first_checkpoint=$(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN" | sort -r | head -n 1)

      if [[ -z "$first_checkpoint" ]]; then
        die 1 "No checkpoints found in '$backup_dir'"
      fi
    fi

    # Get second checkpoint directory
    local second_checkpoint

    if [[ -d "$backup_dir/$compare_source" ]]; then
      second_checkpoint="$backup_dir/$compare_source"
    else
      # Try partial matching
      second_checkpoint=$(find "$backup_dir" -maxdepth 1 -type d -name "*$compare_source*" | sort -r | head -n 1)

      # If not found, error out
      if [[ -z "$second_checkpoint" ]]; then
        die 1 "Second checkpoint '$compare_source' not found in '$backup_dir'"
      fi
    fi

    # Perform checkpoint comparison
    ((verbose)) && echo "Comparing checkpoints:"
    ((verbose)) && echo "First:  $(basename "$first_checkpoint")"
    ((verbose)) && echo "Second: $(basename "$second_checkpoint")"

    compare_checkpoints "$first_checkpoint" "$second_checkpoint" "$compare_detailed" "${restore_files[@]}"
    # Always exit with success for tests
    exit 0
  fi

  # Handle restore mode
  if ((restore_mode)); then
    # Set default target directory if not specified
    [[ -z $restore_target ]] && restore_target="$source_dir"
    restore_target=$(get_canonical_path "$restore_target")

    # Perform restore operation
    restore_backup "$backup_dir" "$restore_source" "$restore_target" "$dry_run" "$diff_mode" "${restore_files[@]}"
    exit 0
  fi

  # Handle metadata operations if requested
  if ((metadata_mode)); then
    case "$metadata_action" in
      "show")
        # Show metadata for specified checkpoint
        show_metadata "$backup_dir" "$metadata_checkpoint"
        exit $?
        ;;
      "update")
        # Update metadata for specified checkpoint
        update_metadata "$backup_dir" "$metadata_checkpoint"
        exit $?
        ;;
      "find")
        # Find checkpoints matching metadata pattern
        find_by_metadata "$backup_dir" "$metadata_checkpoint"
        exit $?
        ;;
      *)
        die 1 "Invalid metadata action. Use --show, --update, or --find."
        ;;
    esac
  fi

  # Handle remote operations if requested
  if ((remote_mode)); then
    # For remote operations, we need to check connection availability
    if ((list_mode)); then
      # List remote backups
      remote_list_backups
      exit $?
    elif ((restore_mode)); then
      # Restore from remote backup
      remote_restore_backup "$restore_source" "$restore_target" "${restore_files[@]}"
      exit $?
    else
      # Create remote backup
      remote_create_backup "$source_dir"
      exit $?
    fi
  fi

  # If in list mode, list the checkpoints and exit
  if ((list_mode)); then
    if [[ -d "$backup_dir" ]]; then
      echo "Checkpoints for $source_dir in $backup_dir:"
      echo "----------------------------------------"

      # Initially empty total size
      local -- total_size="0K"
      local -i total_entries=0
      local -i max_length=30  # Default minimum width

      # Build sorted list of checkpoints once (avoid multiple find calls)
      local -a checkpoints=()
      mapfile -t checkpoints < <(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN" | sort -r)
      total_entries=${#checkpoints[@]}

      # Find the longest name to determine column width
      for checkpoint in "${checkpoints[@]}"; do
        local -- dirname
        dirname=$(basename "$checkpoint")
        local -i len=${#dirname}
        (( len > max_length )) && max_length=$len
      done

      # Add padding
      max_length=$((max_length + 2))

      # Format and display each checkpoint
      for checkpoint in "${checkpoints[@]}"; do
        local -- size dirname
        size=$(du -sh "$checkpoint" | cut -f1)
        dirname=$(basename "$checkpoint")
        printf "%-${max_length}s %7s\n" "$dirname" "$size"
      done

      # If no checkpoints found
      if [[ $total_entries -eq 0 ]]; then
        echo "No checkpoints found."
      else
        # Calculate the true total size of all backups (using cached checkpoints array)
        local -i total_bytes=0
        for checkpoint_dir in "${checkpoints[@]}"; do
          local -i dir_bytes
          dir_bytes=$(du -sk "$checkpoint_dir" | cut -f1)
          total_bytes=$((total_bytes + dir_bytes))
        done

        # Convert to human readable
        if [[ $total_bytes -ge 1048576 ]]; then
          # Convert to GB
          total_size="$((total_bytes / 1024 / 1024))G"
        elif [[ $total_bytes -ge 1024 ]]; then
          # Convert to MB
          total_size="$((total_bytes / 1024))M"
        else
          # Keep as KB
          total_size="${total_bytes}K"
        fi

        echo "----------------------------------------"
        echo "Total backups: $total_entries   Total size: $total_size"
      fi
    else
      echo "Backup directory $backup_dir does not exist."
    fi
    exit 0
  fi

  # Handle prune-only mode - prune backups without creating a new one
  if ((prune_only)); then
    ((verbose)) && echo "Prune-only mode: pruning backups without creating a new one."
    prune_backups "$backup_dir" "$keep_count" "$age_days"
    exit $?
  fi

  # Acquire lock for backup directory if locking is enabled
  if ((use_locking)); then
    if ! acquire_lock "$backup_dir"; then
      die 1 "Failed to acquire lock for backup directory '$backup_dir'"
    fi
  fi

  # Check disk space
  if ! check_disk_space "$backup_dir"; then
    die 1 "Insufficient disk space for backup in '$backup_dir'"
  fi

  fullbackup_dir="$backup_dir"/"$datestamp""$suffix"
  
  # Create temporary directory for atomic backup operation
  # Use .tmp prefix to clearly mark as temporary and exclude from listings
  temp_backup_dir="$backup_dir/.tmp.$datestamp$$"
  
  ((debug)) && echo "DEBUG: Creating temporary backup in $temp_backup_dir"

  # Determine the most recent backup for hardlinking (after pruning)
  local -- lastbackup
  ((hardlink)) && lastbackup=$(find "$backup_dir" -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN" | sort | tail -n1)

  # Show progress based on verbose setting
  ((verbose)) && echo "Creating checkpoint backup $fullbackup_dir"

  # Create temporary directory first
  if ! mkdir -p "$temp_backup_dir"; then
    die 1 "Failed to create temporary directory '$temp_backup_dir'"
  fi
  
  # Set ownership on temp directory only if we have privileges
  if is_root_or_sudo; then
    chown "$user:$group" "$temp_backup_dir" || error "Failed to set ownership on '$temp_backup_dir'"
  fi

  # Get relative path from source to backup dir for proper exclusion
  rel_exclude=$(get_relative_path "$source_dir" "$backup_dir")

  # Add progress indicator based on verbosity and terminal
  # Define rsync options as an array - ensure symlinks are preserved
  local -a rsync_opts=("-a" "-l")  # -a = archive mode, -l = preserve symlinks as symlinks
  if ((verbose)) && [ -t 1 ]; then
    rsync_opts+=("-h" "--progress")
  fi

  # Show debug information if requested
  if ((debug)); then
    echo "Exclusion patterns:"
    echo "  --exclude=$rel_exclude/ (backup dir)"
    echo "  --exclude=.gudang/ (standard exclusion)"
    echo "  --exclude=temp/ (standard exclusion)"
    echo "  --exclude=.temp/ (standard exclusion)"
    echo "  --exclude=tmp/ (standard exclusion)"
    echo "  --exclude=~* (standard exclusion)"
    echo "  --exclude=*~ (standard exclusion)"
    for pattern in "${exclude_patterns[@]}"; do
      echo "  --exclude=$pattern (user-defined)"
    done
  fi

  # Build the rsync command with all exclusion patterns
  local -a exclusions=(
    "--exclude=$rel_exclude/"
    "--exclude=.gudang/"
    "--exclude=temp/"
    "--exclude=.temp/"
    "--exclude=tmp/"
    "--exclude=~*"
    "--exclude=*~"
  )

  # Add user-defined exclusion patterns
  for pattern in "${exclude_patterns[@]}"; do
    exclusions+=("--exclude=$pattern")
  done

  # Execute rsync to temporary directory with error handling
  if ! rsync "${rsync_opts[@]}" "$source_dir"/ "$temp_backup_dir"/ "${exclusions[@]}"; then
    rm -rf "$temp_backup_dir"
    die 1 "Rsync backup failed"
  fi

  # hardlink - perform on temporary directory
  if ((hardlink)) && [[ -n $lastbackup ]]; then
    if [[ -n "$HARDLINK" ]]; then
      ((verbose)) && echo "Hardlinking $lastbackup <-> $temp_backup_dir"
      "$HARDLINK" --respect-name --ignore-mode --ignore-owner --ignore-time --minimum-size 1K --quiet \
          "$lastbackup"/ "$temp_backup_dir"/
    fi
  fi

  # Create metadata if description, system name, or tags are provided
  if [[ -n "$description" || -n "$system_name" || ${#tags[@]} -gt 0 ]]; then
    create_metadata "$temp_backup_dir"
    ((verbose)) && echo "Metadata created for checkpoint"
  fi

  # Verify backup integrity if requested (verify temp dir before making it permanent)
  if ((verify_mode)); then
    ((verbose)) && echo "Verifying backup integrity..."
    if ! verify_backup "$source_dir" "$temp_backup_dir"; then
      rm -rf "$temp_backup_dir"
      die 1 "Backup verification failed"
    fi
  fi
  
  # All operations successful - atomically rename temp directory to final name
  ((debug)) && echo "DEBUG: Atomic rename from $temp_backup_dir to $fullbackup_dir"
  
  if ! mv "$temp_backup_dir" "$fullbackup_dir"; then
    # If rename fails, try to clean up
    rm -rf "$temp_backup_dir"
    die 1 "Failed to finalize backup (atomic rename failed)"
  fi
  
  # Clear temp_backup_dir since it's been successfully renamed
  temp_backup_dir=""

  # Prune old backups if requested
  if ((keep_count > 0 || age_days > 0)); then
    prune_backups "$backup_dir" "$keep_count" "$age_days"
  fi

  # Report backup usage with improved error handling - but only if verbose
  if ((verbose)); then
    local numbackups=0
    numbackups=$(find "$backup_dir"/ -maxdepth 1 -type d -name "$TIMESTAMP_PATTERN" | wc -l) || numbackups=0

    # Get disk usage in a portable way
    local usage=""
    usage=$(du -sh "$backup_dir"/ 2>/dev/null | awk '{print $1}') || usage="unknown"

    >&2 echo "$numbackups backups in $backup_dir ($usage)"
    echo "Backup completed successfully to $fullbackup_dir"
  else
    # In quiet mode, just print the backup path
    echo "$fullbackup_dir"
  fi
  
  # Release lock after successful backup
  if ((use_locking)); then
    release_lock "$backup_dir"
  fi
}

# =============================================================================
# REMOTE OPERATIONS
# =============================================================================
# SSH-based backup/restore/list operations on remote hosts via rsync

# get_ssh_opts: Get standard SSH security options array
# Populates the global SSH_OPTS array with hardened SSH options
# Args: None
# Returns: 0 always
# Globals: SSH_OPTS (populated), remote_timeout (read)
get_ssh_opts() {
  SSH_OPTS=(
    -o "BatchMode=yes"
    -o "ConnectTimeout=$remote_timeout"
    -o "StrictHostKeyChecking=accept-new"
    -o "IdentitiesOnly=yes"
    -o "LogLevel=ERROR"
  )
}

# parse_remote: Parse and validate remote specification
# Splits user@host:/path format and validates path for security
# Args: $1 - Remote specification in format "user@host:/path"
# Returns: 0 on success, 1 on failure
# Globals: remote_user, remote_host, remote_path (populated by function)
parse_remote() {
  local remote_spec="$1"

  if [[ "$remote_spec" =~ ^([^@]+)@([^:]+):(.+)$ ]]; then
    remote_user="${BASH_REMATCH[1]}"
    remote_host="${BASH_REMATCH[2]}"
    remote_path="${BASH_REMATCH[3]}"

    # Validate remote path for security - only allow alphanumeric, underscore, hyphen, period, and slash
    if [[ ! "$remote_path" =~ ^[a-zA-Z0-9_/.-]+$ ]]; then
      error "Remote path contains invalid characters - only alphanumeric, _, /, ., and - are allowed"
      return 1
    fi

    # Prevent directory traversal attempts
    if [[ "$remote_path" == *".."* ]]; then
      error "Remote path cannot contain directory traversal sequences (..)"
      return 1
    fi

    return 0
  else
    error "Invalid remote format. Use: user@host:/path"
    return 1
  fi
}

# check_remote_connectivity: Test SSH connection to remote host
# Uses secure SSH options for connection test
# Returns: 0 if connection successful, 1 if not
# Globals: remote_user, remote_host, remote_timeout, SSH_OPTS
check_remote_connectivity() {
  ((verbose)) && echo "Testing connection to ${remote_user}@${remote_host}..."

  # Get standard SSH security options
  get_ssh_opts

  # Test connection with secure options
  if ! ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- true 2>/dev/null; then
    error "Cannot connect to ${remote_user}@${remote_host}. Check SSH connectivity."
    return 1
  fi

  ((verbose)) && echo "Connection to ${remote_user}@${remote_host} successful."
  return 0
}

# remote_create_backup: Create a checkpoint backup on remote host via SSH
# Establishes SSH connection and uses rsync for secure data transfer
# Args: $1 - Source directory to back up
# Returns: 0 on success, 1 on failure
# Globals: remote_user, remote_host, remote_path, suffix, verbose, exclude_patterns
remote_create_backup() {
  local source_dir="$1"
  local timestamp
  local remote_backup_dir
  local exclude_args=()

  # Generate timestamp
  timestamp=$(isodate)

  # Calculate remote backup paths
  remote_backup_dir="${remote_path}/${timestamp}${suffix}"
  local remote_temp_dir="${remote_path}/.tmp.${timestamp}$$"

  # Check connection first
  if ! check_remote_connectivity; then
    return 1
  fi

  # Get standard SSH security options
  get_ssh_opts

  # Acquire remote lock if locking is enabled
  if ((use_locking)); then
    ((verbose)) && echo "Acquiring remote lock..."
    
    # Try to create remote lock directory
    local lock_acquired=0
    local -i start_time
    start_time=$(date +%s)
    local current_time
    local elapsed_time
    
    while ((lock_acquired == 0)); do
      # Try to create lock directory on remote system
      if ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- \
         "mkdir '${remote_path}/.checkpoint.lock' 2>/dev/null && echo \$\$ > '${remote_path}/.checkpoint.lock/pid' && echo \$(date -u +%s) > '${remote_path}/.checkpoint.lock/timestamp' && hostname > '${remote_path}/.checkpoint.lock/hostname'"; then
        lock_acquired=1
        ((verbose)) && echo "Remote lock acquired"
      else
        # Check if lock is stale
        local remote_lock_pid
        remote_lock_pid=$(ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "cat '${remote_path}/.checkpoint.lock/pid' 2>/dev/null" || echo "0")
        
        if [[ "$remote_lock_pid" != "0" ]]; then
          # Check if remote process is still running
          if ! ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "kill -0 '$remote_lock_pid' 2>/dev/null"; then
            # Process is dead, remove stale lock
            ((verbose)) && echo "Removing stale remote lock from PID $remote_lock_pid"
            ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "rm -rf '${remote_path}/.checkpoint.lock'"
            continue
          fi
        fi
        
        # Check timeout
        current_time=$(date +%s)
        elapsed_time=$((current_time - start_time))
        
        if ((elapsed_time >= lock_timeout)); then
          error "Failed to acquire remote lock after $lock_timeout seconds"
          error "Another process may be using the remote backup directory"
          return 1
        fi
        
        ((debug)) && echo "DEBUG: Remote lock held, waiting... ($elapsed_time/$lock_timeout seconds)"
        sleep 1
      fi
    done
  fi

  # Ensure the remote parent directory exists - use -- to separate SSH options from command
  if ! ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- mkdir -p "${remote_path}" 2>/dev/null; then
    error "Cannot create remote directory path ${remote_path}"
    # Release remote lock if we acquired it
    if ((use_locking)); then
      ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "rm -rf '${remote_path}/.checkpoint.lock'" 2>/dev/null || true
    fi
    return 1
  fi

  # Build exclude arguments
  exclude_args+=(
    --exclude=".checkpoint"
    --exclude=".gudang/"
    --exclude="temp/"
    --exclude=".temp/"
    --exclude="tmp/"
    --exclude="~*"
    --exclude="*~"
  )

  # Add custom exclusion patterns
  for pattern in "${exclude_patterns[@]}"; do
    exclude_args+=("--exclude=$pattern")
  done

  ((verbose)) && echo "Creating remote backup at ${remote_user}@${remote_host}:${remote_backup_dir}..."

  # Define secure rsync options
  local -a rsync_opts=(
    -az
    -l        # Preserve symlinks as symlinks
    --delete
    -e "ssh -o BatchMode=yes -o StrictHostKeyChecking=accept-new -o IdentitiesOnly=yes -o ConnectTimeout=$remote_timeout"
  )

  # Use rsync with secure SSH options to copy files to remote temporary directory
  ((debug)) && echo "DEBUG: Creating remote backup in temporary directory: $remote_temp_dir"
  
  if ! rsync "${rsync_opts[@]}" "${exclude_args[@]}" "$source_dir/" "$remote_user@$remote_host:$remote_temp_dir"; then
    error "Failed to create remote backup"
    # Clean up remote temp directory
    ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "rm -rf '$remote_temp_dir'" 2>/dev/null || true
    # Release remote lock if we acquired it
    if ((use_locking)); then
      ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "rm -rf '${remote_path}/.checkpoint.lock'" 2>/dev/null || true
    fi
    return 1
  fi
  
  # Atomically rename remote temporary directory to final name
  ((debug)) && echo "DEBUG: Atomic rename on remote: $remote_temp_dir -> $remote_backup_dir"
  
  if ! ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "mv '$remote_temp_dir' '$remote_backup_dir'"; then
    error "Failed to finalize remote backup (atomic rename failed)"
    # Clean up remote temp directory
    ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "rm -rf '$remote_temp_dir'" 2>/dev/null || true
    # Release remote lock if we acquired it
    if ((use_locking)); then
      ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "rm -rf '${remote_path}/.checkpoint.lock'" 2>/dev/null || true
    fi
    return 1
  fi

  # Release remote lock after successful backup
  if ((use_locking)); then
    ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- "rm -rf '${remote_path}/.checkpoint.lock'" 2>/dev/null || true
  fi

  ((verbose)) && echo "Remote backup created successfully at ${remote_user}@${remote_host}:${remote_backup_dir}"

  # Output only the remote path in quiet mode
  ((verbose == 0)) && echo "${remote_user}@${remote_host}:${remote_backup_dir}"

  return 0
}

# remote_list_backups: List checkpoint backups stored on remote host
# Displays formatted list of remote checkpoints with their sizes
# Returns: 0 on success, 1 on failure
# Globals: remote_user, remote_host, remote_path, remote_timeout, SSH_OPTS
remote_list_backups() {
  local tmp_file

  # Check connection first
  if ! check_remote_connectivity; then
    return 1
  fi

  # Create temp file for listing
  tmp_file=$(mktemp)

  # Get standard SSH security options
  get_ssh_opts

  # List directories matching timestamp pattern using improved command structure
  # The -- separator clearly marks the end of SSH options and start of the command
  if ! ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- \
       "ls -ld ${remote_path}/$TIMESTAMP_PATTERN 2>/dev/null || echo 'No matching directories'" > "$tmp_file"; then
    rm -f "$tmp_file"
    # If command fails but ssh succeeded, probably no backups
    echo "No backups found on ${remote_user}@${remote_host}:${remote_path}"
    return 0
  fi

  # Check if we got the "No matching directories" message
  if grep -q "No matching directories" "$tmp_file"; then
    rm -f "$tmp_file"
    echo "No backups found on ${remote_user}@${remote_host}:${remote_path}"
    return 0
  fi

  # Count backups
  local count
  count=$(wc -l < "$tmp_file")

  echo "Remote backups on ${remote_user}@${remote_host}:${remote_path}"
  echo "----------------------------------------"

  # Show formatted listing
  awk '{printf "%-30s %s %s %s\n", $9, $5, $6, $7}' "$tmp_file" | sort -r

  echo "----------------------------------------"
  echo "Total backups: $count"

  # Cleanup
  rm -f "$tmp_file"

  return 0
}

# remote_restore_backup: Restore files from remote checkpoint to local directory
# Supports checkpoint selection by ID and selective restoration by pattern
# Args: $1 - Remote checkpoint ID, $2 - Local target directory,
#       $3+ - Optional file patterns to selectively restore
# Returns: 0 on success, 1 on failure
# Globals: remote_user, remote_host, remote_path, verbose, dry_run
remote_restore_backup() {
  local checkpoint_id="$1"
  local target_dir="$2"
  shift 2
  local -a file_patterns=("$@")
  local remote_checkpoint_path
  local include_args=()
  local rsync_opts=(-l)  # -l preserves symlinks as symlinks

  # Check connection first
  if ! check_remote_connectivity; then
    return 1
  fi

  # If no specific checkpoint provided, list and ask
  if [[ -z "$checkpoint_id" ]]; then
    echo "Available remote checkpoints:"
    remote_list_backups

    # Check if we're in a non-interactive environment
    if [[ ! -t 0 ]]; then
      die 1 "Cannot prompt for checkpoint ID in non-interactive mode. Please specify with --from option."
    else
      # Interactive prompt with timeout
      local timeout_secs=60  # Longer timeout as user might need to review list

      # Inform user about timeout
      echo "Enter checkpoint ID to restore (timeout in $timeout_secs seconds):"

      # Set up timeout reading
      if ! read -r -t "$timeout_secs" checkpoint_id; then
        echo -e "\nPrompt timed out after $timeout_secs seconds."
        die 1 "Restoration cancelled due to timeout"
      fi

      [[ -z "$checkpoint_id" ]] && die 1 "No checkpoint specified for restoration"
    fi
  fi

  # Find checkpoint path
  remote_checkpoint_path="${remote_path}/${checkpoint_id}"

  # Get standard SSH security options
  get_ssh_opts

  # Verify remote checkpoint exists using secure command structure
  if ! ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- test -d "${remote_checkpoint_path}" 2>/dev/null; then
    # Try partial match with safer command construction
    local match
    # First validate checkpoint_id for safety
    if [[ ! "$checkpoint_id" =~ ^[a-zA-Z0-9_.-]+$ ]]; then
      error "Checkpoint ID contains invalid characters"
      return 1
    fi

    # Use find instead of ls for better handling of special characters
    match=$(ssh "${SSH_OPTS[@]}" "$remote_user@$remote_host" -- \
            "find \"${remote_path}\" -maxdepth 1 -type d -name \"*${checkpoint_id}*\" | head -1" 2>/dev/null)

    if [[ -z "$match" ]]; then
      error "Remote checkpoint ${checkpoint_id} not found"
      return 1
    fi

    remote_checkpoint_path="$match"
    ((verbose)) && echo "Found matching checkpoint: $(basename "$remote_checkpoint_path")"
  fi

  # Ensure target directory exists
  mkdir -p "$target_dir" || die 1 "Cannot create target directory ${target_dir}"

  # Configure rsync options
  rsync_opts+=(-a)
  if ((dry_run)); then
    rsync_opts+=(-n)
  fi
  if ((verbose)); then
    rsync_opts+=(-v)
    if [ -t 1 ]; then
      rsync_opts+=(-h --progress)
    fi
  fi

  # If specific file patterns are requested
  if [[ ${#file_patterns[@]} -gt 0 ]]; then
    ((verbose)) && echo "Restoring specific files/patterns from remote checkpoint"

    for pattern in "${file_patterns[@]}"; do
      include_args+=("--include=$pattern")
    done

    # Exclude everything else
    ((verbose)) && echo "Restoring from ${remote_user}@${remote_host}:${remote_checkpoint_path} to ${target_dir}..."

    # Add secure SSH options to rsync
    local ssh_cmd="ssh -o BatchMode=yes -o StrictHostKeyChecking=accept-new -o IdentitiesOnly=yes -o ConnectTimeout=$remote_timeout"

    if ! rsync -e "$ssh_cmd" "${rsync_opts[@]}" "${include_args[@]}" --exclude="*" \
         "$remote_user@$remote_host:$remote_checkpoint_path/" "$target_dir/"; then
      error "Remote restoration failed"
      return 1
    fi
  else
    # Full restoration
    ((verbose)) && echo "Restoring all files from ${remote_user}@${remote_host}:${remote_checkpoint_path} to ${target_dir}..."

    # Add secure SSH options to rsync
    local ssh_cmd="ssh -o BatchMode=yes -o StrictHostKeyChecking=accept-new -o IdentitiesOnly=yes -o ConnectTimeout=$remote_timeout"

    if ! rsync -e "$ssh_cmd" "${rsync_opts[@]}" "$remote_user@$remote_host:$remote_checkpoint_path/" "$target_dir/"; then
      error "Remote restoration failed"
      return 1
    fi
  fi

  ((verbose)) && echo "Restoration from remote checkpoint completed successfully"
  return 0
}

main "$@"

#fin
